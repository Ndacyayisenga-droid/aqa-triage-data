{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShantKhatri/aqa-triage-data/blob/filtered-pr-retrieve/Automated_Fine_Tuning_Data_Harvester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Setup and Dependencies\n",
        "### This cell installs the necessary Python libraries and clones the OpenJ9 repository.\n"
      ],
      "metadata": {
        "id": "xYewO0k51rj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyGithub python-dateutil -q"
      ],
      "metadata": {
        "id": "_2GNpSnK1jm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5659230e-63e2-4bea-b55d-5ae2c1ed1404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/416.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/416.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.5/416.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/856.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('openj9'):\n",
        "    !git clone https://github.com/eclipse-openj9/openj9.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSVYl9CzlVoI",
        "outputId": "38594c61-35fc-43c5-c2f9-238ba88c0920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'openj9'...\n",
            "remote: Enumerating objects: 292916, done.\u001b[K\n",
            "remote: Counting objects: 100% (650/650), done.\u001b[K\n",
            "remote: Compressing objects: 100% (341/341), done.\u001b[K\n",
            "remote: Total 292916 (delta 510), reused 309 (delta 309), pack-reused 292266 (from 4)\u001b[K\n",
            "Receiving objects: 100% (292916/292916), 192.70 MiB | 22.14 MiB/s, done.\n",
            "Resolving deltas: 100% (222019/222019), done.\n",
            "Updating files: 100% (10335/10335), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import subprocess\n",
        "from github import Github, RateLimitExceededException\n",
        "from getpass import getpass\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil import tz\n",
        "\n",
        "# --- Configuration ---\n",
        "REPO_PATH = \"openj9\"\n",
        "TRAINING_DATA_FILE = \"training_data.jsonl\"\n",
        "PROCESSED_LOG_FILE = \"processed_prs_log.txt\"\n",
        "GITHUB_REPO = \"eclipse-openj9/openj9\"\n",
        "# Keywords to find \"fix\" pull requests\n",
        "FIX_KEYWORDS = ['fix', 'fixes', 'revert', 'reverts', 'corrects', 'resolves']"
      ],
      "metadata": {
        "id": "006WXbTo1pcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- GitHub Authentication ---\n",
        "# To search 10k or more PRs, a token is MANDATORY.\n",
        "# Create a Personal Access Token (PAT) here: https://github.com/settings/tokens\n",
        "try:\n",
        "    if 'github_token' in locals() and github_token:\n",
        "        g = Github(github_token)\n",
        "        print(\"Authenticated with existing token.\")\n",
        "    else:\n",
        "        raise NameError\n",
        "except NameError:\n",
        "    print(\"A GitHub Personal Access Token is REQUIRED to search 10,000 PRs.\")\n",
        "    github_token = getpass(\"Enter your GitHub Token: \")\n",
        "    g = Github(github_token)\n",
        "\n",
        "try:\n",
        "    repo = g.get_repo(GITHUB_REPO)\n",
        "    rate_limit = g.get_rate_limit()\n",
        "    print(f\"Successfully connected to the {GITHUB_REPO} repository.\")\n",
        "    print(f\"API Rate Limit: {rate_limit.core.remaining}/{rate_limit.core.limit} requests remaining.\")\n",
        "    if rate_limit.core.remaining < 1000:\n",
        "         print(\"WARNING: Your remaining API requests are low. The script may fail.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to connect to repository. Please check your token and repository name. Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybt03R0H2mJQ",
        "outputId": "64d91651-2d62-463e-eb74-4a0fec26838a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated with existing token.\n",
            "✅ Successfully connected to the eclipse-openj9/openj9 repository.\n",
            "❌ Failed to connect to repository. Please check your token and repository name. Error: 'RateLimitOverview' object has no attribute 'core'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Data Generation Script\n",
        "\n",
        "def get_commit_author_date(sha):\n",
        "    \"\"\"Gets the author date of a specific commit and returns it as a datetime object.\"\"\"\n",
        "    try:\n",
        "        os.chdir(REPO_PATH)\n",
        "        # Use %ai for author date in ISO 8601 format\n",
        "        cmd = [\"git\", \"show\", \"-s\", \"--format=%ai\", sha]\n",
        "        date_str = subprocess.check_output(cmd).decode('utf-8').strip()\n",
        "        os.chdir(\"..\")\n",
        "        # Manually parse the ISO 8601 format with timezone\n",
        "        dt = datetime.strptime(date_str[:-6], '%Y-%m-%d %H:%M:%S ')\n",
        "        offset_hours = int(date_str[-5:-2])\n",
        "        offset_minutes = int(date_str[-2:])\n",
        "        offset = timedelta(hours=offset_hours, minutes=offset_minutes)\n",
        "        if date_str[-6] == '-':\n",
        "            dt -= offset\n",
        "        else:\n",
        "            dt += offset\n",
        "        return dt.replace(tzinfo=tz.tzutc())\n",
        "    except Exception as e:\n",
        "        # Silently fail to avoid cluttering the output\n",
        "        pass\n",
        "    if os.path.basename(os.getcwd()) == REPO_PATH:\n",
        "        os.chdir(\"..\")\n",
        "    return None\n",
        "\n",
        "def find_commits_for_day(commit_date):\n",
        "    \"\"\"Finds all commits for a given day in the New York timezone.\"\"\"\n",
        "    if not commit_date:\n",
        "        return None, None\n",
        "\n",
        "    ny_tz = tz.gettz('America/New_York')\n",
        "    commit_date_ny = commit_date.astimezone(ny_tz)\n",
        "\n",
        "    start_of_day_ny = commit_date_ny.replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "    end_of_day_ny = start_of_day_ny + timedelta(days=1) - timedelta(seconds=1)\n",
        "\n",
        "    # Format for git log command\n",
        "    since_str = start_of_day_ny.strftime('%Y-%m-%d %H:%M:%S %z')\n",
        "    until_str = end_of_day_ny.strftime('%Y-%m-%d %H:%M:%S %z')\n",
        "\n",
        "    try:\n",
        "        os.chdir(REPO_PATH)\n",
        "        cmd = [\"git\", \"log\", \"--pretty=%H\", f\"--since='{since_str}'\", f\"--until='{until_str}'\", \"--reverse\"]\n",
        "        commit_list = subprocess.check_output(\" \".join(cmd), shell=True).decode('utf-8').strip().splitlines()\n",
        "        os.chdir(\"..\")\n",
        "\n",
        "        if not commit_list:\n",
        "            return None, None\n",
        "\n",
        "        if len(commit_list) > 1:\n",
        "            good_sha = commit_list[0]\n",
        "            bad_sha = commit_list[-1]\n",
        "            return good_sha, bad_sha\n",
        "        else:\n",
        "             os.chdir(REPO_PATH)\n",
        "             parent_cmd = [\"git\", \"log\", \"-n\", \"1\", \"--pretty=%P\", commit_list[0]]\n",
        "             parent_sha_list = subprocess.check_output(parent_cmd).decode('utf-8').strip().split()\n",
        "             os.chdir(\"..\")\n",
        "             if parent_sha_list:\n",
        "                return parent_sha_list[0], commit_list[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    if os.path.basename(os.getcwd()) == REPO_PATH:\n",
        "        os.chdir(\"..\")\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def find_culprit_sha_in_body(body):\n",
        "    \"\"\"Parses a PR body to find a commit SHA.\"\"\"\n",
        "    if not body:\n",
        "        return None\n",
        "    # Regex to find a 7 to 40 character hexadecimal string, often preceded by context words\n",
        "    match = re.search(r'(?:fixe?s?|revert?s?|commit|sha)\\s*:?\\s*#?\\s*([0-9a-f]{7,40})\\b', body, re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    # Broader search if the first one fails\n",
        "    match = re.search(r'\\b[0-9a-f]{7,40}\\b', body)\n",
        "    if match:\n",
        "        return match.group(0)\n",
        "    return None\n",
        "\n",
        "\n",
        "print(\"Helper functions are defined. Proceed to the final step to run the script.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Cdx1g82c6B",
        "outputId": "8b244eca-9b39-43f8-ae2c-7d39b1703ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions are defined. Proceed to the final step to run the script.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting the data harvesting process...\")\n",
        "print(f\"Searching for PRs with keywords: {FIX_KEYWORDS}\")\n",
        "\n",
        "# Clear previous log file\n",
        "if os.path.exists(PROCESSED_LOG_FILE):\n",
        "    os.remove(PROCESSED_LOG_FILE)\n",
        "\n",
        "try:\n",
        "    pulls = repo.get_pulls(state='closed', sort='updated', direction='desc')\n",
        "\n",
        "    training_examples_count = 0\n",
        "    culprit_found_count = 0\n",
        "\n",
        "    for i, pr in enumerate(pulls):\n",
        "        if i >= 10000:\n",
        "            print(\"\\nReached search limit of 10,000 PRs.\")\n",
        "            break\n",
        "\n",
        "        if (i % 100 == 0) and (i > 0):\n",
        "            print(f\"...scanned {i} PRs...\")\n",
        "\n",
        "        if not pr.merged:\n",
        "            continue\n",
        "\n",
        "        # Check if the title contains any of our keywords\n",
        "        if any(keyword in pr.title.lower() for keyword in FIX_KEYWORDS):\n",
        "\n",
        "            culprit_sha = find_culprit_sha_in_body(pr.body)\n",
        "            if not culprit_sha:\n",
        "                continue\n",
        "\n",
        "            # Log this PR as it contains a culprit SHA\n",
        "            culprit_found_count += 1\n",
        "            pr_info = f\"PR #{pr.number}: {pr.title} (Culprit SHA Found: {culprit_sha[:10]}) - URL: {pr.html_url}\\n\"\n",
        "            with open(PROCESSED_LOG_FILE, 'a') as log_file:\n",
        "                log_file.write(pr_info)\n",
        "\n",
        "            culprit_date = get_commit_author_date(culprit_sha)\n",
        "            if not culprit_date:\n",
        "                continue\n",
        "\n",
        "            good_sha, bad_sha = find_commits_for_day(culprit_date)\n",
        "            if not good_sha or not bad_sha:\n",
        "                continue\n",
        "\n",
        "except RateLimitExceededException:\n",
        "    print(\"\\n GITHUB API RATE LIMIT EXCEEDED.\")\n",
        "    print(\"The script has been stopped. Please wait for an hour or use a different token.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n",
        "finally:\n",
        "    print(f\"\\n\\nHarvesting complete. Scanned approximately {i+1} PRs.\")\n",
        "    print(f\"Found {culprit_found_count} PRs with a potential culprit SHA.\")\n",
        "    print(f\"Successfully generated {training_examples_count} training examples.\")\n",
        "\n",
        "    print(f\"\\n- A full log of all PRs with culprit SHAs has been saved to '{PROCESSED_LOG_FILE}'.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the data harvesting process...\n",
            "Searching for PRs with keywords: ['fix', 'fixes', 'revert', 'reverts', 'corrects', 'resolves']\n",
            "...scanned 100 PRs...\n",
            "...scanned 200 PRs...\n",
            "...scanned 300 PRs...\n",
            "...scanned 400 PRs...\n",
            "...scanned 500 PRs...\n",
            "...scanned 600 PRs...\n",
            "...scanned 700 PRs...\n",
            "...scanned 800 PRs...\n",
            "...scanned 900 PRs...\n",
            "...scanned 1000 PRs...\n",
            "...scanned 1100 PRs...\n",
            "...scanned 1200 PRs...\n",
            "...scanned 1300 PRs...\n",
            "...scanned 1400 PRs...\n",
            "...scanned 1500 PRs...\n",
            "...scanned 1600 PRs...\n",
            "...scanned 1700 PRs...\n",
            "...scanned 1800 PRs...\n",
            "...scanned 1900 PRs...\n",
            "...scanned 2000 PRs...\n",
            "...scanned 2100 PRs...\n",
            "...scanned 2200 PRs...\n",
            "...scanned 2300 PRs...\n",
            "...scanned 2400 PRs...\n",
            "...scanned 2500 PRs...\n",
            "...scanned 2600 PRs...\n",
            "...scanned 2700 PRs...\n",
            "...scanned 2800 PRs...\n",
            "...scanned 2900 PRs...\n",
            "...scanned 3000 PRs...\n",
            "...scanned 3100 PRs...\n",
            "...scanned 3200 PRs...\n",
            "...scanned 3300 PRs...\n",
            "...scanned 3400 PRs...\n",
            "...scanned 3500 PRs...\n",
            "...scanned 3600 PRs...\n",
            "...scanned 3700 PRs...\n",
            "...scanned 3800 PRs...\n",
            "...scanned 3900 PRs...\n",
            "...scanned 4000 PRs...\n",
            "...scanned 4100 PRs...\n",
            "...scanned 4200 PRs...\n",
            "...scanned 4300 PRs...\n",
            "...scanned 4400 PRs...\n",
            "...scanned 4500 PRs...\n",
            "...scanned 4600 PRs...\n",
            "...scanned 4700 PRs...\n",
            "...scanned 4800 PRs...\n",
            "...scanned 4900 PRs...\n",
            "...scanned 5000 PRs...\n",
            "...scanned 5100 PRs...\n",
            "...scanned 5200 PRs...\n",
            "...scanned 5300 PRs...\n",
            "...scanned 5400 PRs...\n",
            "...scanned 5500 PRs...\n",
            "...scanned 5600 PRs...\n",
            "...scanned 5700 PRs...\n",
            "...scanned 5800 PRs...\n",
            "...scanned 5900 PRs...\n",
            "...scanned 6000 PRs...\n",
            "...scanned 6100 PRs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Request GET /repos/eclipse-openj9/openj9/pulls/12215 failed with 403: Forbidden\n",
            "INFO:github.GithubRetry:Request GET /repos/eclipse-openj9/openj9/pulls/12215 failed with 403: Forbidden\n",
            "Setting next backoff to 11.486647s\n",
            "INFO:github.GithubRetry:Setting next backoff to 11.486647s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...scanned 6200 PRs...\n",
            "...scanned 6300 PRs...\n",
            "...scanned 6400 PRs...\n",
            "...scanned 6500 PRs...\n",
            "...scanned 6600 PRs...\n",
            "...scanned 6700 PRs...\n",
            "...scanned 6800 PRs...\n",
            "...scanned 6900 PRs...\n",
            "...scanned 7000 PRs...\n",
            "...scanned 7100 PRs...\n",
            "...scanned 7200 PRs...\n",
            "...scanned 7300 PRs...\n",
            "...scanned 7400 PRs...\n",
            "...scanned 7500 PRs...\n",
            "...scanned 7600 PRs...\n",
            "...scanned 7700 PRs...\n",
            "...scanned 7800 PRs...\n",
            "...scanned 7900 PRs...\n",
            "...scanned 8000 PRs...\n",
            "...scanned 8100 PRs...\n",
            "...scanned 8200 PRs...\n",
            "...scanned 8300 PRs...\n",
            "...scanned 8400 PRs...\n",
            "...scanned 8500 PRs...\n",
            "...scanned 8600 PRs...\n",
            "...scanned 8700 PRs...\n",
            "...scanned 8800 PRs...\n",
            "...scanned 8900 PRs...\n",
            "...scanned 9000 PRs...\n",
            "...scanned 9100 PRs...\n",
            "...scanned 9200 PRs...\n",
            "...scanned 9300 PRs...\n",
            "...scanned 9400 PRs...\n",
            "...scanned 9500 PRs...\n",
            "...scanned 9600 PRs...\n",
            "...scanned 9700 PRs...\n",
            "...scanned 9800 PRs...\n",
            "...scanned 9900 PRs...\n",
            "\n",
            "Reached search limit of 10,000 PRs.\n",
            "\n",
            "\n",
            "Harvesting complete. Scanned approximately 10001 PRs.\n",
            "Found 131 PRs with a potential culprit SHA.\n",
            "Successfully generated 0 training examples.\n",
            "\n",
            "- A full log of all PRs with culprit SHAs has been saved to 'processed_prs_log.txt'.\n",
            "- Your training data is ready for review in 'training_data.jsonl'.\n",
            "\n",
            "IMPORTANT: Remember to manually review and edit the 'Reasoning' and 'Recommendation' fields for each entry in the training data file.\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o3TmZDQ0vCM",
        "outputId": "e9c8b3c4-954e-476d-a0dd-1f23e83bc5a2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}